{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the data to improve data! There is not enough variance hence cant seperate classes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"recipe_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count vectorizer\n",
    "vocab = pickle.load(open(\"recipe_text_features_countvec/train_name_countvectorizer.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10892"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict = vocab.vocabulary_\n",
    "len(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "spares_recipe_name = scipy.sparse.load_npz('recipe_text_features_countvec/train_name_vec.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_name = spares_recipe_name.toarray()\n",
    "recipe_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1976\n",
      "1 2916\n",
      "1 3871\n",
      "1 4437\n",
      "1 8202\n",
      "1 9458\n",
      "1 10597\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(recipe_name[0])):\n",
    "    if recipe_name[0][i]!=0:\n",
    "        print(recipe_name[0][i], end=\" \")\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing doc2vec files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "heading_name = []\n",
    "heading_steps = []\n",
    "heading_ingr = []\n",
    "for i in range(100):\n",
    "    heading_name.append(\"name\"+str(i))\n",
    "    heading_steps.append(\"steps\"+str(i))\n",
    "    heading_ingr.append(\"ingr\"+str(i))\n",
    "    \n",
    "recipe_train = pd.read_csv('recipe_train.csv')\n",
    "n_steps = recipe_train['n_steps']\n",
    "n_ingr = recipe_train['n_ingredients']\n",
    "duration_label = recipe_train['duration_label']\n",
    "\n",
    "name = pd.read_csv('recipe_text_features_doc2vec100/train_name_doc2vec100.csv', names=heading_name)\n",
    "steps = pd.read_csv('recipe_text_features_doc2vec100/train_steps_doc2vec100.csv', names=heading_steps)\n",
    "ingr = pd.read_csv('recipe_text_features_doc2vec100/train_ingr_doc2vec100.csv', names=heading_ingr)\n",
    "\n",
    "data = name.join(steps).join(ingr).join(n_steps).join(n_ingr)\n",
    "labeled_data = name.join(steps).join(ingr).join(n_steps).join(n_ingr).join(duration_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name0</th>\n",
       "      <th>name1</th>\n",
       "      <th>name2</th>\n",
       "      <th>name3</th>\n",
       "      <th>name4</th>\n",
       "      <th>name5</th>\n",
       "      <th>name6</th>\n",
       "      <th>name7</th>\n",
       "      <th>name8</th>\n",
       "      <th>name9</th>\n",
       "      <th>...</th>\n",
       "      <th>ingr92</th>\n",
       "      <th>ingr93</th>\n",
       "      <th>ingr94</th>\n",
       "      <th>ingr95</th>\n",
       "      <th>ingr96</th>\n",
       "      <th>ingr97</th>\n",
       "      <th>ingr98</th>\n",
       "      <th>ingr99</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>n_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.138903</td>\n",
       "      <td>-0.105632</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.184168</td>\n",
       "      <td>-0.060962</td>\n",
       "      <td>0.158132</td>\n",
       "      <td>0.183160</td>\n",
       "      <td>-0.047310</td>\n",
       "      <td>-0.094243</td>\n",
       "      <td>-0.190823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.250643</td>\n",
       "      <td>0.214695</td>\n",
       "      <td>-0.018045</td>\n",
       "      <td>0.395938</td>\n",
       "      <td>-0.057779</td>\n",
       "      <td>0.336876</td>\n",
       "      <td>0.230647</td>\n",
       "      <td>0.143468</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.050503</td>\n",
       "      <td>-0.009516</td>\n",
       "      <td>0.103751</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>-0.077112</td>\n",
       "      <td>0.064507</td>\n",
       "      <td>-0.077452</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.011587</td>\n",
       "      <td>-0.273610</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.122143</td>\n",
       "      <td>-0.188637</td>\n",
       "      <td>0.096245</td>\n",
       "      <td>0.296148</td>\n",
       "      <td>0.098384</td>\n",
       "      <td>-0.124963</td>\n",
       "      <td>-0.195799</td>\n",
       "      <td>-0.210086</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.017546</td>\n",
       "      <td>-0.065912</td>\n",
       "      <td>0.018216</td>\n",
       "      <td>-0.136358</td>\n",
       "      <td>-0.157555</td>\n",
       "      <td>0.012741</td>\n",
       "      <td>-0.090726</td>\n",
       "      <td>-0.172800</td>\n",
       "      <td>-0.013132</td>\n",
       "      <td>-0.139782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127930</td>\n",
       "      <td>-0.271923</td>\n",
       "      <td>-0.188931</td>\n",
       "      <td>-0.154470</td>\n",
       "      <td>-0.174869</td>\n",
       "      <td>-0.341245</td>\n",
       "      <td>-0.060525</td>\n",
       "      <td>0.080168</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.192465</td>\n",
       "      <td>0.100614</td>\n",
       "      <td>-0.135092</td>\n",
       "      <td>-0.045592</td>\n",
       "      <td>-0.084184</td>\n",
       "      <td>0.011720</td>\n",
       "      <td>-0.273193</td>\n",
       "      <td>-0.112106</td>\n",
       "      <td>-0.342789</td>\n",
       "      <td>-0.048324</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.259047</td>\n",
       "      <td>0.107682</td>\n",
       "      <td>-0.259195</td>\n",
       "      <td>-0.065767</td>\n",
       "      <td>-0.065660</td>\n",
       "      <td>-0.207306</td>\n",
       "      <td>-0.167152</td>\n",
       "      <td>0.492161</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.294862</td>\n",
       "      <td>0.072540</td>\n",
       "      <td>-0.079729</td>\n",
       "      <td>-0.123215</td>\n",
       "      <td>-0.006412</td>\n",
       "      <td>-0.029505</td>\n",
       "      <td>0.014645</td>\n",
       "      <td>0.058601</td>\n",
       "      <td>0.113420</td>\n",
       "      <td>-0.282019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131887</td>\n",
       "      <td>0.215795</td>\n",
       "      <td>0.119587</td>\n",
       "      <td>-0.063841</td>\n",
       "      <td>-0.107087</td>\n",
       "      <td>-0.281038</td>\n",
       "      <td>-0.136156</td>\n",
       "      <td>0.063560</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>0.079531</td>\n",
       "      <td>-0.152311</td>\n",
       "      <td>-0.108301</td>\n",
       "      <td>0.245858</td>\n",
       "      <td>0.027275</td>\n",
       "      <td>0.123829</td>\n",
       "      <td>0.170607</td>\n",
       "      <td>-0.097053</td>\n",
       "      <td>-0.195209</td>\n",
       "      <td>-0.161817</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110938</td>\n",
       "      <td>0.007777</td>\n",
       "      <td>-0.021177</td>\n",
       "      <td>0.016590</td>\n",
       "      <td>-0.189764</td>\n",
       "      <td>-0.068398</td>\n",
       "      <td>-0.190228</td>\n",
       "      <td>0.083059</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>0.175133</td>\n",
       "      <td>-0.062132</td>\n",
       "      <td>-0.037974</td>\n",
       "      <td>-0.036284</td>\n",
       "      <td>-0.065828</td>\n",
       "      <td>0.023028</td>\n",
       "      <td>-0.064448</td>\n",
       "      <td>-0.003984</td>\n",
       "      <td>-0.072117</td>\n",
       "      <td>-0.204766</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019811</td>\n",
       "      <td>0.015345</td>\n",
       "      <td>0.050862</td>\n",
       "      <td>0.087614</td>\n",
       "      <td>0.594146</td>\n",
       "      <td>0.507868</td>\n",
       "      <td>0.109975</td>\n",
       "      <td>-0.047240</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>0.056546</td>\n",
       "      <td>0.125747</td>\n",
       "      <td>-0.161598</td>\n",
       "      <td>0.088675</td>\n",
       "      <td>-0.130160</td>\n",
       "      <td>-0.099027</td>\n",
       "      <td>-0.086974</td>\n",
       "      <td>-0.129478</td>\n",
       "      <td>-0.043179</td>\n",
       "      <td>-0.026247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111844</td>\n",
       "      <td>0.219837</td>\n",
       "      <td>0.034625</td>\n",
       "      <td>0.033108</td>\n",
       "      <td>-0.518219</td>\n",
       "      <td>0.229315</td>\n",
       "      <td>-0.024256</td>\n",
       "      <td>-0.351173</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>-0.001341</td>\n",
       "      <td>0.042503</td>\n",
       "      <td>0.026502</td>\n",
       "      <td>0.187291</td>\n",
       "      <td>0.063780</td>\n",
       "      <td>0.078871</td>\n",
       "      <td>-0.180524</td>\n",
       "      <td>-0.104264</td>\n",
       "      <td>0.017374</td>\n",
       "      <td>-0.337967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.157026</td>\n",
       "      <td>-0.158611</td>\n",
       "      <td>0.375092</td>\n",
       "      <td>0.225296</td>\n",
       "      <td>-0.409948</td>\n",
       "      <td>-0.642923</td>\n",
       "      <td>0.512482</td>\n",
       "      <td>-0.925799</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>0.121345</td>\n",
       "      <td>-0.045553</td>\n",
       "      <td>-0.015056</td>\n",
       "      <td>-0.097100</td>\n",
       "      <td>0.141332</td>\n",
       "      <td>0.199203</td>\n",
       "      <td>0.098336</td>\n",
       "      <td>-0.064405</td>\n",
       "      <td>0.263377</td>\n",
       "      <td>-0.305463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137772</td>\n",
       "      <td>0.195448</td>\n",
       "      <td>-0.206056</td>\n",
       "      <td>0.092833</td>\n",
       "      <td>-0.045537</td>\n",
       "      <td>-0.035035</td>\n",
       "      <td>-0.058196</td>\n",
       "      <td>0.035302</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows Ã— 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          name0     name1     name2     name3     name4     name5     name6  \\\n",
       "0     -0.138903 -0.105632  0.211538  0.184168 -0.060962  0.158132  0.183160   \n",
       "1      0.050503 -0.009516  0.103751  0.001047 -0.077112  0.064507 -0.077452   \n",
       "2      0.017546 -0.065912  0.018216 -0.136358 -0.157555  0.012741 -0.090726   \n",
       "3     -0.192465  0.100614 -0.135092 -0.045592 -0.084184  0.011720 -0.273193   \n",
       "4      0.294862  0.072540 -0.079729 -0.123215 -0.006412 -0.029505  0.014645   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "39995  0.079531 -0.152311 -0.108301  0.245858  0.027275  0.123829  0.170607   \n",
       "39996  0.175133 -0.062132 -0.037974 -0.036284 -0.065828  0.023028 -0.064448   \n",
       "39997  0.056546  0.125747 -0.161598  0.088675 -0.130160 -0.099027 -0.086974   \n",
       "39998 -0.001341  0.042503  0.026502  0.187291  0.063780  0.078871 -0.180524   \n",
       "39999  0.121345 -0.045553 -0.015056 -0.097100  0.141332  0.199203  0.098336   \n",
       "\n",
       "          name7     name8     name9  ...    ingr92    ingr93    ingr94  \\\n",
       "0     -0.047310 -0.094243 -0.190823  ... -0.250643  0.214695 -0.018045   \n",
       "1      0.008811  0.011587 -0.273610  ... -0.122143 -0.188637  0.096245   \n",
       "2     -0.172800 -0.013132 -0.139782  ...  0.127930 -0.271923 -0.188931   \n",
       "3     -0.112106 -0.342789 -0.048324  ... -0.259047  0.107682 -0.259195   \n",
       "4      0.058601  0.113420 -0.282019  ...  0.131887  0.215795  0.119587   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "39995 -0.097053 -0.195209 -0.161817  ... -0.110938  0.007777 -0.021177   \n",
       "39996 -0.003984 -0.072117 -0.204766  ... -0.019811  0.015345  0.050862   \n",
       "39997 -0.129478 -0.043179 -0.026247  ...  0.111844  0.219837  0.034625   \n",
       "39998 -0.104264  0.017374 -0.337967  ... -0.157026 -0.158611  0.375092   \n",
       "39999 -0.064405  0.263377 -0.305463  ...  0.137772  0.195448 -0.206056   \n",
       "\n",
       "         ingr95    ingr96    ingr97    ingr98    ingr99  n_steps  \\\n",
       "0      0.395938 -0.057779  0.336876  0.230647  0.143468        6   \n",
       "1      0.296148  0.098384 -0.124963 -0.195799 -0.210086        9   \n",
       "2     -0.154470 -0.174869 -0.341245 -0.060525  0.080168       15   \n",
       "3     -0.065767 -0.065660 -0.207306 -0.167152  0.492161       10   \n",
       "4     -0.063841 -0.107087 -0.281038 -0.136156  0.063560        6   \n",
       "...         ...       ...       ...       ...       ...      ...   \n",
       "39995  0.016590 -0.189764 -0.068398 -0.190228  0.083059        6   \n",
       "39996  0.087614  0.594146  0.507868  0.109975 -0.047240       15   \n",
       "39997  0.033108 -0.518219  0.229315 -0.024256 -0.351173        5   \n",
       "39998  0.225296 -0.409948 -0.642923  0.512482 -0.925799        7   \n",
       "39999  0.092833 -0.045537 -0.035035 -0.058196  0.035302        6   \n",
       "\n",
       "       n_ingredients  \n",
       "0                 12  \n",
       "1                  5  \n",
       "2                 10  \n",
       "3                  8  \n",
       "4                  5  \n",
       "...              ...  \n",
       "39995             13  \n",
       "39996             16  \n",
       "39997              8  \n",
       "39998             17  \n",
       "39999             11  \n",
       "\n",
       "[40000 rows x 302 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgbc = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cross_val_score(xgbc, data, duration_label, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuning test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(data, duration_label, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:59:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "119.25272226333618 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "xgbc.fit(X_train, Y_train)\n",
    "\n",
    "fin = time.time()\n",
    "\n",
    "print(fin-start, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.717"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbc.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc_eta1 = xgb.XGBClassifier(learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "xgbc_eta1.fit(X_train, Y_train)\n",
    "\n",
    "fin = time.time()\n",
    "\n",
    "print(fin-start, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgbc_eta1.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc_eta2 = xgb.XGBClassifier(learning_rate = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "224.28854656219482\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "xgbc_eta2.fit(X_train, Y_train)\n",
    "\n",
    "fin = time.time()\n",
    "\n",
    "print(fin-start, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7185"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbc_eta2.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.94578125"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbc_eta2.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc_colsam1 = xgb.XGBClassifier(learning_rate = 0.2, colsample_bytree = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:58:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "44.88545870780945 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "xgbc_colsam1.fit(X_train, Y_train)\n",
    "\n",
    "fin = time.time()\n",
    "\n",
    "print(fin-start, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.717625"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbc_colsam1.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93796875"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbc_colsam1.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_range = np.arange(0.1, 0.35, 0.05)\n",
    "max_depth_range = np.arange(3,16,1)\n",
    "min_child_weight_range = np.arange(1,9,2)\n",
    "gamma_range = np.arange(0, 0.5, 0.1)\n",
    "colsample_bytree_range = np.arange(0.3, 0.8, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test with feature n_steps and n_ingredients only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(data[['n_steps', 'n_ingredients']], duration_label, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:58:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "1.4029359817504883 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "xgbc_eta2.fit(X_train2, Y_train2)\n",
    "\n",
    "fin = time.time()\n",
    "\n",
    "print(fin-start, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6365"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbc_eta2.score(X_test2, Y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrc = LogisticRegression(solver = 'saga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.13733434677124 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "lrc.fit(X_train, Y_train)\n",
    "\n",
    "fin = time.time()\n",
    "\n",
    "print(fin-start, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7275"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrc.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrc1 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.728337049484253 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "lrc1.fit(X_train, Y_train)\n",
    "\n",
    "fin = time.time()\n",
    "\n",
    "print(fin-start, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.725625"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrc1.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrc2 = LogisticRegression(max_iter = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.66108751296997 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "lrc2.fit(X_train, Y_train)\n",
    "\n",
    "fin = time.time()\n",
    "\n",
    "print(fin-start, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.728"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrc2.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrc3 = LogisticRegression(max_iter = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.8420729637146 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "lrc3.fit(X_train, Y_train)\n",
    "\n",
    "fin = time.time()\n",
    "\n",
    "print(fin-start, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.728125"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrc3.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for overfiiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7348125"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrc3.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test classifier on iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = load_iris()\n",
    "\n",
    "cross_val_score(xgbc, x.data, x.target, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare different models on a selected set of feature(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008998870849609375 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "gnb.fit(X_train2, Y_train2)\n",
    "\n",
    "fin = time.time()\n",
    "\n",
    "print(fin-start, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.619875"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.score(X_test2, Y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform custom binning on n_steps and n_ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_fast = labeled_data.loc[labeled_data['duration_label'] == 1].loc[:,['n_steps']].squeeze().array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_fast_mean = np.mean(n_steps_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_fast_std = np.std(n_steps_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_med = labeled_data.loc[labeled_data['duration_label'] == 2].loc[:,['n_steps']].squeeze().array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_med_mean = np.mean(n_steps_med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_med_std = np.std(n_steps_med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_slow = labeled_data.loc[labeled_data['duration_label'] == 3].loc[:,['n_steps']].squeeze().array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_slow_mean = np.mean(n_steps_slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_slow_std = np.std(n_steps_slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ingredients_fast = labeled_data.loc[labeled_data['duration_label'] == 1].loc[:,['n_steps']].squeeze().array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ingredients_med = labeled_data.loc[labeled_data['duration_label'] == 2].loc[:,['n_steps']].squeeze().array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ingredients_slow = labeled_data.loc[labeled_data['duration_label'] == 3].loc[:,['n_steps']].squeeze().array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from https://stackoverflow.com/questions/10138085/python-plot-normal-distribution\n",
    "\n",
    "x = np.linspace(n_steps_slow_mean - 3*n_steps_slow_std, n_steps_fast_mean + 3*n_steps_fast_std, 100)\n",
    "plt.plot(x, stats.norm.pdf(x, n_steps_fast_mean, n_steps_fast_std))\n",
    "plt.plot(x, stats.norm.pdf(x, n_steps_med_mean, n_steps_med_std))\n",
    "plt.plot(x, stats.norm.pdf(x, n_steps_slow_mean, n_steps_slow_std))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform custom doc2vec (tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
